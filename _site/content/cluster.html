<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Multipass and Bitcoin Cache Machine | Bitcoin Cache Machine</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Multipass and Bitcoin Cache Machine" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Privacy-preserving Bitcoin Payment infrastructure for home and office." />
<meta property="og:description" content="Privacy-preserving Bitcoin Payment infrastructure for home and office." />
<link rel="canonical" href="http://localhost:4000/content/cluster.html" />
<meta property="og:url" content="http://localhost:4000/content/cluster.html" />
<meta property="og:site_name" content="Bitcoin Cache Machine" />
<script type="application/ld+json">
{"@type":"WebPage","url":"http://localhost:4000/content/cluster.html","headline":"Multipass and Bitcoin Cache Machine","description":"Privacy-preserving Bitcoin Payment infrastructure for home and office.","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=92419ec9030e5a41186c8c2f74a9bbd9205958c9">
  </head>
  <body>
    <!-- <a id="skip-to-content" href="#content">Skip to the content.</a> -->

    <header class="page-header" role="banner">
      <h1 class="project-name">Bitcoin Cache Machine</h1>
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="multipass-and-bitcoin-cache-machine">Multipass and Bitcoin Cache Machine</h1>

<p><a href="https://github.com/CanonicalLtd/multipass"><code class="highlighter-rouge">multipass</code></a> is software (available as a <a href="https://snapcraft.io/">snap</a>) that orchestrates the creation, management, and maintenance of QEMU/KVM VMs. Multipass is installed on the <code class="highlighter-rouge">dev machine</code> when running provisioning scripts found in <code class="highlighter-rouge">$BCM_LOCAL_GIT_REPO_DIR/lxd_projects/</code> BCM scripts use the <code class="highlighter-rouge">multipass</code> CLI to create one or more hardware-enforced VMs. Each VM created by BCM multipass scripts runs a cloud-based Ubuntu image.</p>

<p>The scripts in this directory help you get started testing BCM quickly. Running <code class="highlighter-rouge">./up_multipass_cluster.sh -c CLUS1 -m 3</code> at the terminal will create a series of multipass VMs. Each VM will be named CLUS1-00, CLUS1-01, …  The last parameter is the number of member nodes you want in your LXD cluster.  In the example, there will be 4 VMs total, one for the cluster master (assumed) and 3 additional member nodes. If you run <code class="highlighter-rouge">./up_multipass_cluster.sh CLUS1</code> (without the integer parameter), a single VM will be created. In all cases, <code class="highlighter-rouge">up_multipass_cluster.sh</code> leaves you with one or more Ubuntu VMs that are up-to-date and have necessary dependencies. Furthermore, LXD in each VM is <a href="https://lxd.readthedocs.io/en/latest/clustering/#preseed">preseeded</a> and configured to operate in a cohesive cluster.</p>

<p>Each VM represents available CPU, memory, disk, and networking that you can use to deploy BCM components.</p>

<h1 id="multipass-requirements">multipass Requirements</h1>

<p>To run multipass, you must have a computer capable of running QEMU/KVM-based VMs which is typical with a developer or server machine. In some cases, you might have to visit your BIOS to ensure that hardware-based virtualization features are enabled. Low-end laptops typical of the DEV market may not have the necessary hardware requirements to run BCM in a multipass VM. However, you can always run BCM on <a href="./lxd/README.md">bare-metal</a>!</p>

<p>To install <code class="highlighter-rouge">multipass</code> manually, run the following command. Also remember that <code class="highlighter-rouge">$BCM_LOCAL_GIT_REPO_DIR/lxd_projects/setup.sh</code> installs <code class="highlighter-rouge">multipass</code> on the <code class="highlighter-rouge">dev machine</code> during provisioning as well.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>snap install lxd <span class="nt">--candidate</span>
</code></pre></div></div>

<h1 id="script-descriptions">Script descriptions</h1>

<p>Each section below briefly explains what each script does. The end goal of all the scripts is to deliver one or more VMs, all of which are configured as an LXD cluster. Each VM is a place where you can deploy one or more BCM components!</p>

<blockquote>
  <p>WARNING: You can create a cluster of multipass VMs all on the same host, but you really should have distinct physical hosts to increase your <a href="https://en.wikipedia.org/wiki/Failure_domain">failure domains</a>. Creating a local cluster on your <code class="highlighter-rouge">dev machine</code>, however, is great for testing!</p>
</blockquote>

<h2 id="creation-scripts">Creation Scripts</h2>

<h3 id="up_multipass_clustersh">./up_multipass_cluster.sh</h3>

<p>This is what you’re going to run when in the ./multipass directory. It has 2 parameters: <code class="highlighter-rouge">-c</code> for the cluster name, and <code class="highlighter-rouge">-m</code> for the number of additional nodes beyond 1 you want provisioned.  Pertinent examples,</p>

<ul>
  <li><code class="highlighter-rouge">./up_multipass_cluster.sh -c DEV -m 2</code> – This will provision a total of three multipass VMs each prepended with “DEV”. The VMs will be “DEV-00”, “DEV-01”, and “DEV-02”. This is the recommended command when testing on the <code class="highlighter-rouge">dev machine</code> since it provisions a cluster of machines (representing physical hosts) that allow a quorum to be reached. Of course, BCM works just as well when developing against a single-host cluster.</li>
  <li><code class="highlighter-rouge">./up_multipass_cluster.sh -c DEV</code> – This will provision one multipass VM named “DEV-00”. DEV-00 will still be configured to operate in a LXD cluster even though it hasn’t reached a quorum.</li>
</ul>

<h3 id="stubenvsh">./stub.env.sh</h3>

<p>This script creates the .env file needed for each LXD endpoint. <code class="highlighter-rouge">./stub_env.sh</code> uses the <code class="highlighter-rouge">envsubst</code> command to substitute environment variables from the template files in the ./env/ directory. The resulting file gets stored at <code class="highlighter-rouge">$BCM_RUNTIME_DIR/clusters/$BCM_CLUSTER_NAME/endpoints/$BCM_CLUSTER_ENDPOINT_NAME/.env</code>. This file contains, the VM multipass VM name, the LXD secret (randomly generated), and the multipass CPU, memory, and disk space used during provisioning.</p>

<h3 id="multipass_vm_upsh">./multipass_vm_up.sh</h3>

<p>This script actually creates the VM using the <code class="highlighter-rouge">multipass</code> cli.  The <code class="highlighter-rouge">multipass launch</code> command passes a <a href="https://cloud-init.io/">cloud-init</a> file to the VM for provisioning directly after launch. The static <code class="highlighter-rouge">./cloud_init.yml</code> is used to initially provision ALL multipass hosts (master and members). The <code class="highlighter-rouge">cloud-init</code> file installs all necessary base OS dependencies like <a href="https://en.wikipedia.org/wiki/ZFS">ZFS</a>, which is used as the LXD container storage backend, and <code class="highlighter-rouge">wait-for-it</code>, which is helpful to determine when service come online. (TODO <code class="highlighter-rouge">tor</code> is also installed for optionally exposing the LXD REST API over an authenticated onion service). The cloud-init definition also removes the default LXD client that comes with the Ubuntu base image and instead installs the latest candidate LXD via snap.</p>

<p>This script continues by obtaining the runtime IP address of the multipass VM then passing control over to either <code class="highlighter-rouge">./provision_lxd_master.sh</code> or <code class="highlighter-rouge">./provision_lxd_member.sh</code>, depending on whether the multipass VM is the first host in the cluster, i.e., the host ending in ‘-00’.</p>

<h3 id="provision_lxd_mastersh">provision_lxd_master.sh</h3>

<p>This script starts by creating an LXD preseed file, storing it in <code class="highlighter-rouge">$BCM_RUNTIME_DIR/clusters/$BCM_CLUSTER_NAME/endpoints/$BCM_CLUSTER_ENDPOINT_NAME/lxd/</code>. The resulting file is copied up to the multipass VM then the <code class="highlighter-rouge">lxd init</code> command is issued, passing in the preseed file. After the LXD daemon is configured in the multipass VM, the resulting lxd.cert file in the daemon is copied back to the <code class="highlighter-rouge">dev_machine</code> for subsequent provisioning activities. The lxd.cert is stored in the same directory as the LXD preseed file.</p>

<p><code class="highlighter-rouge">provision_lxd_master.sh</code> completes by adding an LXD remote to the <code class="highlighter-rouge">dev_machine</code> lxd client (via <code class="highlighter-rouge">lxc remote add</code>). Furthermore, the lxc remote is defaulted to first cluster member (i.e., “-00”) via <code class="highlighter-rouge">lxd remote set-default</code>. This allows you to pass control to BCM provisioning scripts in the <code class="highlighter-rouge">$BCM_LOCAL_GIT_REPO_DIR/lxd/</code> directory.</p>

<h3 id="provision_lxd_membersh">provision_lxd_member.sh</h3>

<p><code class="highlighter-rouge">provision_lxd_member.sh</code> performs similar functions to <code class="highlighter-rouge">provision_lxd_master.sh</code> and is required because LXD preseed files for VMs joining an existing cluster is different from the first host in the cluster. All resulting preseed files are stored under <code class="highlighter-rouge">$BCM_RUNTIME_DIR/clusters/$BCM_CLUSTER_NAME/endpoints/$BCM_CLUSTER_ENDPOINT_NAME/lxd/</code>.</p>

<h2 id="destruction-scripts">Destruction Scripts</h2>

<h3 id="destroy_clustersh">./destroy_cluster.sh</h3>

<p>This script iterates over the VMs that have the specified cluster name and deletes them. It also removes related files and directories in <code class="highlighter-rouge">$BCM_RUNTIME_DIR/clusters/$BCM_CLUSTER_NAME</code>. You can initiate this script with the following command.</p>

<p>./destroy_cluster.sh -c DEV</p>

<p>In the example above, “DEV” is the name of the cluster you want destroyed.</p>

<h3 id="destroy_multipasssh">./destroy_multipass.sh</h3>

<p>This script is called by <code class="highlighter-rouge">./destroy_cluster.sh</code> and performs destruction processes scoped to a single VM/LXD endpoint.</p>


      <footer class="site-footer">
    
      <span class="site-footer-owner"><a href="http://localhost:4000">Bitcoin Cache Machine</a> is maintained by <a href="http://github.com/BitcoinCacheMachine">BitcoinCacheMachine</a>.</span>
    
</footer>
    </main>
  </body>
</html>